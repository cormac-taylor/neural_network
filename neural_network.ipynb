{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 | Problem 5: Neural Network\n",
    "#### Cormac Taylor\n",
    "#### I pledge my honor that I have abided by the Stevens Honor System."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: ucimlrepo in ./.venv/lib/python3.13/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in ./.venv/lib/python3.13/site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "- NumPy\n",
    "- Pandas\n",
    "- Sklearn\n",
    "- fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R. Fisher. \"Iris,\" UCI Machine Learning Repository, 1936. [Online]. Available: https://doi.org/10.24432/C56C76.\n",
    "iris = fetch_ucirepo(id=53) \n",
    "\n",
    "raw_X = iris.data.features\n",
    "raw_y = iris.data.targets \n",
    "\n",
    "classes = np.unique(raw_y)\n",
    "print(f\"classes: {classes}\")\n",
    "\n",
    "raw_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_X = np.array(raw_X)\n",
    "raw_y = np.array(raw_y)\n",
    "\n",
    "# standard gaussian on data values\n",
    "X = (raw_X - np.mean(raw_X, axis=0)) / np.std(raw_X, axis=0)\n",
    "\n",
    "# mapping string class to vector \n",
    "class_map = {val: i for (i, val) in enumerate(classes)}\n",
    "y = np.zeros((np.shape(raw_y)[0], np.shape(classes)[0]))\n",
    "for (i, val) in enumerate(raw_y):\n",
    "    y[i][class_map[val[0]]] = 1\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Neural Network (sigmoid; one hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dev.to/shamdasani/build-a-flexible-neural-network-with-backpropagation-in-python\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputSize, outputSize, hiddenSize):\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenSize = hiddenSize\n",
    "        \n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)\n",
    "        self.b1 = np.zeros((1, self.hiddenSize))\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)\n",
    "        self.b2 = np.zeros((1, self.outputSize))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1          # X1 = W1 * X + b1\n",
    "        self.H1 = self.sigmoid(self.Z1)                 # H1 = sigmoid(Z1)\n",
    "        \n",
    "        self.Z2 = np.dot(self.H1, self.W2) + self.b2    # Z2 = W2 * H1 + b2\n",
    "        self.H2 = self.softmax(self.Z2)                 # H2 = sigmoid(Z2)\n",
    "\n",
    "        return self.H2\n",
    "\n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.1):\n",
    "        for _ in range(epochs):\n",
    "            y_hat = self.forward(X)\n",
    "            N_inv = 1 / np.shape(X)[0]\n",
    "            \n",
    "            self.dZ2 = y_hat - y                                                # dZ2 = H2 - y\n",
    "            self.dW2 = N_inv * np.dot(self.H1.T, self.dZ2)                      # dW2 = 1/N * dZ2 * H1^T\n",
    "            self.db2 = N_inv * np.sum(self.dZ2, axis=0, keepdims=True)          # db2 = 1/N * S(dZ1)\n",
    "        \n",
    "            self.dZ1 = np.dot(self.dZ2, self.W2.T) * self.sigmoidPrime(self.H1) # dZ1 = W2^T * dZ2 * H1 * (1 - H1)\n",
    "            self.dW1 = N_inv * np.dot(X.T, self.dZ1)                            # dW1 = 1/N * dZ1 * X^T\n",
    "            self.db1 = N_inv * np.sum(self.dZ1, axis=0, keepdims=True)          # db1 = 1/N * S(dz1)\n",
    "        \n",
    "            self.W2 -= learning_rate * self.dW2\n",
    "            self.b2 -= learning_rate * self.db2\n",
    "            \n",
    "            self.W1 -= learning_rate * self.dW1\n",
    "            self.b1 -= learning_rate * self.db1\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = self.forward(X)\n",
    "        prediction = np.zeros((np.shape(y_hat)[0], np.shape(y_hat)[1]))\n",
    "        argmax = np.argmax(y_hat, axis=1)\n",
    "        for (i, j) in enumerate(argmax):\n",
    "            prediction[i][j] = 1\n",
    "        return prediction\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "\n",
    "        count = 0\n",
    "        for (i, yi) in enumerate(y):\n",
    "            yi_ind = np.argmax(yi)\n",
    "            count += y_hat[i][yi_ind]\n",
    "\n",
    "        return (count / np.shape(y)[0])\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoidPrime(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 98.33%\n",
      "Testing Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_LAYERS = 32\n",
    "nn = NeuralNetwork(np.shape(X_train)[1], np.shape(y_train)[1], HIDDEN_LAYERS)\n",
    "nn.train(X_train, y_train)\n",
    "\n",
    "training_accuracy = nn.accuracy(X_train, y_train)\n",
    "testing_accuracy = nn.accuracy(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {training_accuracy*100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {testing_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Neural Network (ReLU; variable hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dev.to/shamdasani/build-a-flexible-neural-network-with-backpropagation-in-python\n",
    "class ModifiedNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, layer_sizes):\n",
    "        if len(layer_sizes) <= 2:\n",
    "            raise ValueError(\"Must have at least 1 hidden layer. Form: [input, hidden1, hidden2, ..., output]\")\n",
    "\n",
    "        self.LAYER_SIZES = layer_sizes\n",
    "        self.LAYER_SIZES_LENGTH = len(layer_sizes)\n",
    "        self.NUM_TRANSITIONS = len(layer_sizes) - 1\n",
    "\n",
    "        \n",
    "        self.W_arr = [None] * self.NUM_TRANSITIONS\n",
    "        self.b_arr = [None] * self.NUM_TRANSITIONS\n",
    "        for i in range(1, self.LAYER_SIZES_LENGTH):\n",
    "            self.W_arr[i-1] = np.random.randn(self.LAYER_SIZES[i-1], self.LAYER_SIZES[i])\n",
    "            self.b_arr[i-1] = np.zeros((1, self.LAYER_SIZES[i]))\n",
    "            \n",
    "        self.Z_arr = [None] * self.NUM_TRANSITIONS\n",
    "        self.H_arr = [None] * self.NUM_TRANSITIONS\n",
    "        \n",
    "        self.dZ_arr = [None] * self.NUM_TRANSITIONS\n",
    "        self.dW_arr = [None] * self.NUM_TRANSITIONS\n",
    "        self.db_arr = [None] * self.NUM_TRANSITIONS\n",
    "            \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.Z_arr[0] = np.dot(X, self.W_arr[0]) + self.b_arr[0]\n",
    "        self.H_arr[0] = self.ReLU(self.Z_arr[0])\n",
    "\n",
    "        for i in range(1, self.NUM_TRANSITIONS - 1):\n",
    "            self.Z_arr[i] = np.dot(self.H_arr[i-1], self.W_arr[i]) + self.b_arr[i]\n",
    "            self.H_arr[i] = self.ReLU(self.Z_arr[i])\n",
    "\n",
    "        self.Z_arr[self.NUM_TRANSITIONS - 1] = np.dot(self.H_arr[self.NUM_TRANSITIONS - 2], self.W_arr[self.NUM_TRANSITIONS - 1]) + self.b_arr[self.NUM_TRANSITIONS - 1]\n",
    "        self.H_arr[self.NUM_TRANSITIONS - 1] = self.softmax(self.Z_arr[self.NUM_TRANSITIONS - 1])\n",
    "\n",
    "        return self.H_arr[self.NUM_TRANSITIONS - 1]\n",
    "\n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.1):\n",
    "        for _ in range(epochs):\n",
    "            y_hat = self.forward(X)\n",
    "            N_inv = 1 / np.shape(X)[0]\n",
    "            \n",
    "            idx = self.NUM_TRANSITIONS - 1\n",
    "            self.dZ_arr[idx] = y_hat - y\n",
    "            self.dW_arr[idx] = N_inv * np.dot(self.H_arr[idx-1].T, self.dZ_arr[idx])\n",
    "            self.db_arr[idx] = N_inv * np.sum(self.dZ_arr[idx], axis=0, keepdims=True)\n",
    "        \n",
    "            for i in range(self.NUM_TRANSITIONS - 2, 0, -1):\n",
    "                self.dZ_arr[i] = np.dot(self.dZ_arr[i+1], self.W_arr[i+1].T) * self.ReLUPrime(self.H_arr[i])\n",
    "                self.dW_arr[i] = N_inv * np.dot(self.H_arr[i-1].T, self.dZ_arr[i])\n",
    "                self.db_arr[i] = N_inv * np.sum(self.dZ_arr[i], axis=0, keepdims=True)\n",
    "\n",
    "            idx = 0\n",
    "            self.dZ_arr[idx] = np.dot(self.dZ_arr[idx+1], self.W_arr[idx+1].T) * self.ReLUPrime(self.H_arr[idx])\n",
    "            self.dW_arr[idx] = N_inv * np.dot(X.T, self.dZ_arr[idx])\n",
    "            self.db_arr[idx] = N_inv * np.sum(self.dZ_arr[idx], axis=0, keepdims=True)\n",
    "\n",
    "            for i in range(self.NUM_TRANSITIONS - 1, -1, -1):\n",
    "                self.W_arr[i] -= learning_rate * self.dW_arr[i]\n",
    "                self.b_arr[i] -= learning_rate * self.db_arr[i]\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = self.forward(X)\n",
    "        prediction = np.zeros((np.shape(y_hat)[0], np.shape(y_hat)[1]))\n",
    "        argmax = np.argmax(y_hat, axis=1)\n",
    "        for (i, j) in enumerate(argmax):\n",
    "            prediction[i][j] = 1\n",
    "        return prediction\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "\n",
    "        count = 0\n",
    "        for (i, yi) in enumerate(y):\n",
    "            yi_ind = np.argmax(yi)\n",
    "            count += y_hat[i][yi_ind]\n",
    "\n",
    "        return (count / np.shape(y)[0])\n",
    "\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def ReLUPrime(self, x):\n",
    "        sign_x = np.sign(x)\n",
    "        return np.maximum(0, sign_x)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Testing Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [np.shape(X_train)[1], 32, 16, np.shape(y_train)[1]]\n",
    "mnn = ModifiedNeuralNetwork(LAYERS)\n",
    "\n",
    "mnn.train(X_train, y_train)\n",
    "\n",
    "training_accuracy = mnn.accuracy(X_train, y_train)\n",
    "testing_accuracy = mnn.accuracy(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {training_accuracy*100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {testing_accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
